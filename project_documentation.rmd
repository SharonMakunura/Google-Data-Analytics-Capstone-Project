---
title: "Cyclistic Analysis"
author: "Sharon Makunura"
date: '2022-03-24'
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This report summarizes the analysis process I followed in completing my capstone project for the Google Data Analytics Certification.  For this project, I chose track one which analyzed data for Cyclistic Bikeshare.

### 1. Ask

The goal of my analysis is to identify patterns and trends that are unique to casual riders, and differentiate them from annual members.  The analysis will help inform a marketing strategy that targets casual riders to convert them to annual members.  The results will be communicated to the marketing executives of Cyclistic.  
  
  
### 2: Prepare

A reliable public dataset was used to ensure that the data provided was good data.  9 CSV files were downloaded to compile the data for the year 2020.  I scanned through the files in Excel to confirm each contained the same number of variables.  

I then uploaded the data into RStudio Desktop, which .  I installed four libraries for use: readr, tidyverse,dplyr and tidyr.   I loaded the 9 csv files and saved them as dataframe objects.

**NB: To optimize performance the R code for all analysis and output shown here is available for download from [GitHub](https://github.com/SharonMakunura/Google-Data-Analytics-Capstone-Project)**
  
    
### 3: Process  

I began the process by using glimpse function to look through the datasets.

All the datasets contain the same number of variables.  Next, I combined some of the dataframes to compress the number of dataframes I have to look through, without compromising performance.  I combined dataframes for the following periods:

| Dataframe 1 |+  Dataframe 2 |
|:-------:|:------:|
| Q1| Apr | 
| May | June |
| Nov| Dec |
  
  
This resulted in 7 dataframes to work with.  The next step was to check for duplicates.  By using the duplicated function I was able to determine there were no duplicated records in the datasets.  

The next step was to clean the data.  Because of the number of dataframes and the potential for repeating code, I created custom functions to perform the cleaning operations.  The functions performed the following operations:

*  Replace missing values: some rows were missing data for end stations.  Working on the assumption that these were round trips, the missing data was coalesced with the start station data.

*  Format the started_at and ended_at columns as datetime objects.

*  Use the formatted started_at columns to compute and create new columns for day of week and month 

*   Calculate trip duration by subtracting starting time from ending time.

*   Delete all records with duration of less than 0 minutes. 

*  Delete all coordinates from the data frames.
  
    
    
*NB: A comprehensive cleaning log is also available from [GitHub](https://github.com/SharonMakunura/Google-Data-Analytics-Capstone-Project)*
    
    
When completed the structure of the dataframes had the following structure:
  
![dataframe structure after cleaning](https://drive.google.com/file/d/1hsf0v-gGkla789yc5_83lXESG9xKuJ-c/view?usp=sharing)
  

Finally I combined all the dataframes into one.    
  
  
### 4: Analyze  
  
I began the analysis by calculating the average and max length of all the rides using the calculated field duration.  I also created a function to calculate the most common day, which turned out to be Saturday.  The most frequent month was August.
  
  
Next, I created variations of the above analysis by organizing the average and max length of rides by membership type, day and month.  
  
![ave and max by membership type](https://drive.google.com/file/d/1qYWy-d0eOFHiiK2cZxZ0spHqubCXdHKC/view?usp=sharing)
  
![ave and max by day](https://drive.google.com/file/d/1Rpm9Iet4GSqbtT8Zm9aSRM7yhGJDw9ou/view?usp=sharing)
  
![ave and max by month](https://drive.google.com/file/d/1kGz387snofMlVPG320wPSgPWu44jUbyb/view?usp=sharing)
  
  
Next I looked at the actual number of rides, grouping them by membership type, day of week, and month of the year.  
  
![rides by month](https://drive.google.com/file/d/1VojODrcA_enaMEhbNlnNA5v8kN6SGk6Z/view?usp=sharing)
  
![rides by month and member type](https://drive.google.com/file/d/1N0Uzqb8wgHp51u_p_UTQKuocGnIKi7mx/view?usp=sharing)
  
![rides by day](https://drive.google.com/file/d/1ypDmOaUFGZsjceSHBfBscl2vPFTd00q6/view?usp=sharing)
  
![rides by day and member type](https://drive.google.com/file/d/1DMBdrXhyTg_8zR_7xAYe8gCswBUABsN6/view?usp=sharing)
  
I then split the dataframe into two by member type.  The casual riders are the fewer with around 1,3 million records to the 2,2 million records of members.  By running the mode function again I determined that they shared the same frequent month.  However the most common day for casuals is Saturday, while for members it is Wednesday.    
  
I also looked at the different rideable types to determine if there was any distinct pattern, which surprisingly showed none.    
  
Finally, I merged my summaries logically to create two dataframes that I exported to CSV files.  I also exported my formatted complete data set in CSV format.    
  
  

### 5: Share   
  
  
The results suggest that the most significant aspect of casual riders is the trend towards longer bike rides.  The data implies casual riders ride longer, despite taking fewer and more seasonal rides overall.  This is significant for the business if membership is predicated on the number of rides, or if membership rewards have traditionally focused on number of rides.    
  
I needed to share my findings with the Cyclistic, who are detail oriented and sophisticated.  I decided to created my visualizations in Tableau using the combined dataset I exported from R.  I also created some summary tables in Excel.   Finally, I  downloaded all my Tableau sheets as a PowerPoint presentation, which I then edited to create a presentation for the executives.  I then created a separate report detailing my entire analysis process for the marketing analytics team at Cyclistic using RMarkdown and Word.  
  
  
### 6: Act  
  
The aim in this final process was to ensure that I shared the results of my analysis.  My conclusion was that a marketing strategy that aims to convert casual riders to members should appeal to seasonal/weekend riders.  It should also have benefits that accrue from longer rides rather than more frequent rides.  Lastly, I noted that there is opportunity for further analysis particularly related to geographical locations.    
  
To share these insights I utilized two main approached.  I created a GitHub repository [here](https://github.com/SharonMakunura/Google-Data-Analytics-Capstone-Project) to store all the pieces of the project I had accumulated.  Then, I created a portfolio on [Google Sites](https://sites.google.com/view/sharoncmakunura) to display my work.         
  
## Conclusion  
  
This approach to the project allowed me to structure my process and record it for replication. It also enabled me to most of the tools from the course.    






